qqnorm(x3)
qqline(x3)
qqnorm(x4)
qqline(x4)
n = 100
x=sample(1:6, n, replace=TRUE)
mean(x == 6)
set.seed(1)
n = 5
p = 0.5
x1 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
mean(abs(x) > 2)
set.seed(1)
n = 30
p = 0.5
x2 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
mean(abs(x) > 2)
set.seed(1)
n = 30
p = 0.01
x3 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
mean(abs(x) > 2)
set.seed(1)
n = 100
p = 0.01
x4 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
mean(abs(x) > 2)
mypar(2,2)
qqnorm(x1)
qqline(x1)
qqnorm(x2)
qqline(x2)
qqnorm(x3)
qqline(x3)
qqnorm(x4)
qqline(x4)
sides
n = 5
p = 0.5
sides = 1/p
sides
set.seed(1)
n = 5
p = 0.5
x1 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 30
p = 0.5
x2 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 30
p = 0.01
x3 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 100
p = 0.01
x4 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
mypar(2,2)
qqnorm(x1)
qqline(x1)
qqnorm(x2)
qqline(x2)
qqnorm(x3)
qqline(x3)
qqnorm(x4)
qqline(x4)
set.seed(1)
n = 5
p = 0.5
x1 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 30
p = 0.5
x2 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 30
p = 0.01
x3 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 100
p = 0.01
x4 <- replicate(10000, (mean(sample(1:6, n, replace=TRUE) == 6) - p)/sqrt(p*(1-p)/n))
mypar(2,2)
qqnorm(x1)
qqline(x1)
qqnorm(x2)
qqline(x2)
qqnorm(x3)
qqline(x3)
qqnorm(x4)
qqline(x4)
mypar(2,2)
qqnorm(x1)
qqline(x1)
qqnorm(x2)
qqline(x2)
qqnorm(x3)
qqline(x3)
qqnorm(x4)
qqline(x4)
set.seed(1)
n = 5
p = 0.5
sides = 1/p
x1 <- replicate(10000, (mean(sample(1:sides, n, replace=TRUE) == 1) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 30
p = 0.5
x2 <- replicate(10000, (mean(sample(1:sides, n, replace=TRUE) == 1) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 30
p = 0.01
x3 <- replicate(10000, (mean(sample(1:sides, n, replace=TRUE) == 1) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 100
p = 0.01
x4 <- replicate(10000, (mean(sample(1:sides, n, replace=TRUE) == 1) - p)/sqrt(p*(1-p)/n))
mypar(2,2)
qqnorm(x1)
qqline(x1)
qqnorm(x2)
qqline(x2)
qqnorm(x3)
qqline(x3)
qqnorm(x4)
qqline(x4)
set.seed(1)
n = 5
p = 0.5
sides = 1/p
x1 <- replicate(10000, (mean(sample(1:sides, n, replace=TRUE) == 1) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 30
p = 0.5
sides = 1/p
x2 <- replicate(10000, (mean(sample(1:sides, n, replace=TRUE) == 1) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 30
p = 0.01
sides = 1/p
x3 <- replicate(10000, (mean(sample(1:sides, n, replace=TRUE) == 1) - p)/sqrt(p*(1-p)/n))
set.seed(1)
n = 100
p = 0.01
sides = 1/p
x4 <- replicate(10000, (mean(sample(1:sides, n, replace=TRUE) == 1) - p)/sqrt(p*(1-p)/n))
mypar(2,2)
qqnorm(x1)
qqline(x1)
qqnorm(x2)
qqline(x2)
qqnorm(x3)
qqline(x3)
qqnorm(x4)
qqline(x4)
Y <- filter(dat, Diet=="hf") %>% select(Bodyweight) %>% unlist
# CLT and t-distribution
X <- filter(dat, Diet=="chow") %>% select(Bodyweight) %>% unlist
Y <- filter(dat, Diet=="hf") %>% select(Bodyweight) %>% unlist
mean(X)
popsd(X)
sd(X)
z = 2/sqrt(sd(x)^{2/12})
pnorm(-z) + 1 - pnorm(z)
z = 2/sqrt(sd(x)^(2/12)))
z = 2/(sqrt(sd(x)^(2/12)))
z
pnorm(-z) + 1 - pnorm(z)
z = 2/(sqrt(sd(X)^(2/12)))
pnorm(-z) + 1 - pnorm(z)
pnorm(2, mean = mean(X), sd = mean(X)) - pnorm(-2, mean = mean(X), sd = sd(X))
pnorm(2, mean = mean(X), sd = sd(X)) - pnorm(-2, mean = mean(X), sd = sd(X))
2*(1 - pnorm((2*sqrt(12))/sd(X)))
# The estimate of Standard Error
sqrt(((sd(Y)^(2))/12) + ((sd(Y)^(2))/12))
# The estimate of Standard Error
sqrt(((sd(Y)^(2))/12) + ((sd(X)^(2))/12))
# The estimate of Standard Error
se = sqrt(((sd(Y)^(2))/12) + ((sd(X)^(2))/12))
tstat = (mean(Y) - mean(X))/se
tstat
t.test(X, Y)
2*t.test(X, Y)
t.test(X, Y, paired = T)
t.test(X, Y)
t.test(Y, X)
1 - 0.053
pnorm(tstat)
1 - pnorm(tstat)
2*(1 - pnorm(tstat))
t.test(Y, X)
RNGkind("Mersenne-Twister", "Inversion", "Rejection")
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleControlsPopulation.csv"
filename <- basename(url)
download(url, destfile=filename)
x <- unlist( read.csv(filename) )
set.seed(1)
avgs = vector()
s = sample(x, size = 50)
avgs = vector()
for (k in 1:1000) {
s = sample(x, size = 50)
avgs[k] = mean(s)
}
ags
avgs
mean(avgs > 1)
mean((avgs - mean(avgs)) > 1)
set.seed(1)
avgs = vector()
for (k in 1:1000) {
s = sample(x, size = 50)
avgs[k] = mean(s)
}
mean((avgs - mean(avgs)) > 1)
mean(abs((avgs - mean(avgs))) > 1)
# Question 2
library(gapminder)
data(gapminder)
head(gapminder)
x = gapminder %>% filter(year == 1952 & lifeExp > 40 & lifeExp < 60)
x = gapminder %>% filter(year == 1952 & lifeExp > 40 & lifeExp < 60)
gapminder$Boolean = ifelse(year == 1952 & lifeExp > 40 & lifeExp < 60, TRUE, FALSE)
gapminder$Boolean = ifelse(gapminder$year == 1952 &
gapminder$lifeExp > 40 &
gapminder$lifeExp < 60, TRUE, FALSE)
mean(gapminder$Boolean == T)
View(gapminder)
gapminder$Boolean = ifelse(gapminder$year == 1952 &
gapminder$lifeExp > 40 &
gapminder$lifeExp < 60, TRUE, FALSE)
mean(gapminder$Boolean == T)
countries_1952 = gapminder %>% filter(year == 1952)
countries_1952 = countries_1952 %>% filter(lifeExp > 40 &
lifeExp < 60)
View(countries_1952)
p = nrow(gapminder %>% filter(year == 1952))/nrow(countries_1952)
p
p = nrow(countries_1952)/nrow(gapminder %>% filter(year == 1952))
p
help(Foodprice)
??Foodprice
library(Foodprice)
help(CoNA)
help(Foodprice)
??Foodprice
help(CoNA)
help(CoNA)
remove.packages("Foodprice")
install.packages("Foodprice")
install.packages("Foodprice")
install.packages("Foodprice")
library(Foodprice)
install.packages("Foodprice")
library(devtools)
devtools::install_github("Foodprice/Foodprice")
View(Foodprice::TCAC)
View(Foodprice::Mapeo_Sipsa_TCAC)
library(Foodprice)
View(Foodprice::TCAC)
View(Foodprice::Mapeo_Sipsa_TCAC)
data <- DataCol(10, 2022, "Cali")
View(data)
data <- DataCol(09, 2022, "Cali")
data <- DataCol(09, 2022, "Bogotá")
View(Foodprice::Mapeo_Sipsa_TCAC)
library(read)
library(readxl)
data <- readxl::read_excel(file.choose())
View(data)
data <- data %>% filter(codigo %in% c("B099", "B059"))
data[,c(1,3,7, 9, 10, 11, 15:29)]
data2 <- data[,c(1,3,7, 9, 10, 11, 15:29)]
data2
View(data2)
data2 <- data[,c(3,7, 9, 10, 11, 15:29)]
data3 <- melt(data2, "Nombre del alimento")
data3 <- melt(data2)
data3 <- reshape2::melt(data2)
library(rechape2)
View(data3)
ggplot(data3, aes(x = variable, y = value, col = `Nombre del Alimento`)) + geom_line()
ggplot(data3, aes(x = variable, y = value, col = `Nombre del Alimento`)) + geom_line()
ggplot(data3, aes(x = variable, y = value,
col = `Nombre del Alimento`)) +
geom_bar()
ggplot(data3, aes(fill=`Nombre del Alimento`, y=value, x=variable)) +
geom_bar(position="dodge", stat="identity")
ggplot(data3, aes(fill=`Nombre del Alimento`, y=value, x=variable)) +
geom_bar(position="dodge", stat="identity")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
scaled.dat <- scale(data3)
scaled.dat <- scale(data3[2:ncol(data3)])
scaled.dat <- scale(data2[2:ncol(data2)])
colMeans(scaled.dat)  # faster version of apply(scaled.dat, 2, mean)
apply(scaled.dat, 2, sd)
apply(scaled.dat, 2, sd)
scaled.dat <- scale(data2[2:ncol(data2)])
scaled.dat
data2[2:ncol(data2)]<- scale(data2[2:ncol(data2)])
data3 <- melt(data2)
View(data3)
ggplot(data3, aes(fill=`Nombre del Alimento`, y=value, x=variable)) +
geom_bar(position="dodge", stat="identity")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
data2 <- data[,c(3,7, 9, 10, 11, 15:29)]
data2[2:ncol(data2)]<- scale(data2[2:ncol(data2)])
Viw(data2)
View(data2)
data3 <- melt(data2)
data2 <- data2 %>% mutate_all(function(x)
ifelse(is.nan(x), NA, x))
data3 <- melt(data2)
View(data2)
ifelse(is.nan(x), NA, x)) %>% na.omit()
data3 <- melt(data2)
data2 <- data[,c(3,7, 9, 10, 11, 15:29)]
data2[2:ncol(data2)]<- scale(data2[2:ncol(data2)])
data2 <- data2 %>% mutate_all(function(x)
ifelse(is.nan(x), NA, x)) %>% na.omit()
data3 <- melt(data2)
rm(data3)
data2 <- data[,c(3,7, 9, 10, 11, 15:29)]
data2[2:ncol(data2)]<- scale(data2[2:ncol(data2)])
data2 <- data2 %>% mutate_all(function(x)
ifelse(is.nan(x), NA, x))
data2 <- data2 %>% select("Lipidos (g)")
data2 <- data[,c(3,7, 9, 10, 11, 15:29)]
data2[2:ncol(data2)]<- scale(data2[2:ncol(data2)])
data2 <- data2 %>% mutate_all(function(x)
ifelse(is.nan(x), NA, x))
data2[is.na(data2)] <- 0
data3 <- melt(data2)
View(data2)
colnames(data2)[1] <- "Food"
data3 <- melt(data2, id.vars = "Food")
data2 %>% t()
data3 <- data2 %>% t()
View(data3)
library(installr)
updateR()
updateR()
updateR()
updateR()
library(devtools)
devtools::install_github("Foodprice/Foodprice")
library(devtools)
devtools::install_github("Foodprice/Foodprice")
devtools::install_github("Foodprice/Foodprice",
force = TRUE)
library(Foodprice)
x = CoRD(data, serv, diverse)
x = CoRD(data = data_example, serv, diverse)
x = CoRD(data = data_example, serv = serv_example,
diverse = diverse_example)
data = DataCol(12, 2022, "Cali")
data = DataCol(Month = 12, Year = 2022, City =  "Cali")
data = DataCol(Month = 1, Year = 2022, City =  "Cali")
library(Foodprice)
data = DataCol(Month = 1, Year = 2022, City =  "Cali")
library(Foodprice)
data = DataCol(Month = 9, Year = 2022, City =  "Cali")
View(data)
setwd("C:/Users/PC/Desktop/Curso-EDA-2024/")
# Importar formato .xlsx
dataset <- readxl::read_excel("geih_dataset.xlsx")
# Importar formato .xlsx
dataset <- readxl::read_excel("Datos/Formatos/geih_dataset.xlsx")
# Véase las rutas alternativas
dataset <- readxl::read_excel(file.choose())
df2 <- haven::read_sav("Datos/Formatos/geih_dataset.spss")
df3 <- haven::read_dta("Datos/Formatos/geih_dataset.dta")
df4 <- haven::read_sas("Datos/Formatos/geih_dataset.sas")
# Guardemos la base de datos en .RDS
saveRDS(dataset, "Datos/Formatos/geih_dataset.rds")
# Cargar el archivo en .RDS
readRDS("Datos/Formatos/geih_dataset.rds")
# Crear id en la base de datos
dataset$id <- seq(1, nrow(dataset), by = 1)
# Forma estándar:
dataset_2 <- filter(dataset, edad > 25)
# Forma encadenada:
dataset_2 <- dataset %>% filter(edad > 25)
#-----------#
# Tidyverse #
#-----------#
library(tidyverse)
# Crear id en la base de datos
dataset$id <- seq(1, nrow(dataset), by = 1)
# Forma estándar:
dataset_2 <- filter(dataset, edad > 25)
# Forma encadenada:
dataset_2 <- dataset %>% filter(edad > 25)
# Forma estándar:
dataset_3 <- select(dataset, id, area, edad, ingreso) # seleccionar variables
dataset_3 <- filter(dataset_3, edad > 25 & edad < 40) # filtrar para (25, 40)
dataset_3 <- arrange(dataset_3, desc(edad))
# Forma encadenada
dataset_4 <- dataset %>% select(dataset, id, area, edad, ingreso) %>%
filter(dataset_3, edad > 25 & edad < 40) %>% arrange(desc(edad))
# Forma estándar
dataset_4 <- select(dataset, id, edad, sexo, ingreso, cotiza_fondo)
dataset_4 <- filter(dataset_4, cotiza_fondo %in% c("Colpensiones",
"Fondo privado")
& ingreso > 2500000)
dataset_4 <- arrange(dataset_4, desc(ingreso))
# Arrange(): reordenar los datos con base en columnas
# Arrange(dataframe, variables)
new_dataset <- dataset %>% arrange(edad, ingreso)       # notar las primeras filas
new_dataset <- dataset %>% arrange(edad, desc(ingreso)) # notar las primeras filas
# Mutate(): modifica o agrega nuevas variables
new_dataset <- dataset %>% mutate(edad_int = cut(edad,
breaks = seq(0,100, by = 20),
right = F))
new_dataset <- dataset %>% mutate(edad_int = cut(edad,
breaks = seq(0,100, by = 20),
right = F,
labels = c("0-19",
"20-39",
"40-59",
"60-79",
"70-99"))) # Asignar etiquetas
View(new_dataset)
# Count(): contar categorías en una tabla
# Count(dataframe, variable, sort, name)
new_table <- new_dataset %>% count(cotiza_fondo, sort =T, name = "n")
new_table <- new_dataset %>% count(cotiza_fondo, sexo, sort = T, name = "n")
# Filter(): subconjunto de datos definido por una condición lógica
newest_dataset <- new_dataset %>% filter(sexo == "M")
# Group_by(): subconjunto de datos según categorías. (VER FIGURA)
# (Generalmente se emplea con summarize() para descriptivas diferenciadas)
newest_dataset <- new_dataset %>% group_by(area) %>% summarize(mean_y =
mean(ingreso, na.rm = T),
sd_y = sd(ingreso, na.rm = T),
q1_y = quantile(ingreso,0.25, na.rm = T),
q2_y = quantile(ingreso, 0.5, na.rm = T),
q3_y = quantile(ingreso, 0.75, na.rm = T))
# Rename(): renombrar columnas (también rename_with())
newest_dataset <- new_dataset %>% rename(income = ingreso,
sex = sexo,
age = edad) #renombrar
newest_dataset <- new_dataset %>% rename_with(tolower) # Todo a minúsculas
newest_dataset <- new_dataset %>% rename_with(toupper) # Todo a mayúsculas
# Select(): seleccionar de un subconjunto de variables (VER FIGURA)
newest_dataset <- new_dataset %>% select(id, edad, sexo,
ingreso, cotiza_fondo)
# Summarize(): resumen descriptivo general y diferenciado
table_1 <- new_dataset %>% filter(area == "Cali") %>%
summarize(mean_y = mean(ingreso, na.rm = T),
sd_y = sd(ingreso, na.rm = T)) # Resumen descriptivo con filtro
table_2 <- new_dataset %>% group_by(area) %>%
summarize(mean_y = mean(ingreso, na.rm = T),
sd_y = sd(ingreso, na.rm = T)) # Resumen descriptivo diferenciado
# Resumen descriptivo aplicado a varias columnas
table_3 <- new_dataset %>% group_by(area) %>% summarise(across(c("edad", "ingreso"),
~ mean(.x, na.rm = T)))
# Resumen descriptivo aplicado a varias columnas: todas las variables numéricas
table_4 <- new_dataset %>% select(-c(id)) %>% group_by(area) %>% summarise(across(where(is.numeric),
~ mean(.x, na.rm = T)))
# Resumen descriptivo: múltiples funciones a múltiples columnas
table_5 <-  new_dataset %>% select(-c(id)) %>% group_by(area) %>% summarise(across(c("edad", "horas_semana"),
list(mean = mean,
sd = sd)))
# ¿Y si la función arroja un data frame?
md_df <- function(x){
data.frame(mean = mean(x, na.rm = T),
sd = sd(x, na.rm = T))
}
table_5 <-  new_dataset %>% group_by(area) %>% summarise(across(c("edad"), md_df))
# Nos centramos en las personas que cotizan
new_dataset2 <- new_dataset %>% filter(ingreso > 2000000 &
ingreso < 10000000 &
cotiza_fondo != "No cotiza")
ggplot2::ggplot(new_dataset2, aes(x = edad,
y = ingreso,
color = cotiza_fondo))+
geom_point()
ggplot2::ggplot(new_dataset2, aes(x = edad,
y = ingreso/1000,
color = cotiza_fondo))+
geom_point() + labs(
title = "Ingreso laboral y edad diferenciado según plan de pensiones",
caption = "Fuente: Gran Encuesta Integrada de Hogares - diciembre 2023",
x = "Edad (años cumplidos)",
y = "Ingreso laboral (miles $)",
col = "Plan de pensiones"
)
# Ajustar el color
library(RColorBrewer)
ggplot2::ggplot(new_dataset2, aes(x = edad,
y = ingreso/1000,
color = cotiza_fondo))+
geom_point() + labs(
title = "Ingreso laboral y edad diferenciado según plan de pensiones",
caption = "Fuente: Gran Encuesta Integrada de Hogares - diciembre 2023",
x = "Edad (años cumplidos)",
y = "Ingreso laboral (miles $)",
col = "Plan de pensiones") +
scale_color_brewer(palette = "PuOr")
# Gráfico en ggplot2 con facetas
# Incorporamos el plan de pensiones como una faceta
ggplot2::ggplot(new_dataset2, aes(x = edad,
y = ingreso/1000,
color = cotiza_fondo))+
geom_point() + facet_wrap(~cotiza_fondo, scale = "free_y") + labs(
title = "Ingreso laboral y edad diferenciado según plan de pensiones",
caption = "Fuente: Gran Encuesta Integrada de Hogares - diciembre 2023",
x = "Edad (años cumplidos)",
y = "Ingreso laboral (miles $)",
col = "Plan de pensiones") +
scale_color_brewer(palette = "PuOr")
